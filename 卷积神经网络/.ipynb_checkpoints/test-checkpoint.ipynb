{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca2998e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通过下⾯的LeNet代码，可以看出⽤深度学习框架实现此类模型⾮常简单。我们只需要实例化⼀\n",
    "# 个Sequential块并将需要的层连接在⼀起。\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32711aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92de7593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),  # 经过卷积和池化后，得到的图像尺寸为5*5\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96162f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t torch.Size([1, 400])\n",
      "Linear output shape: \t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t torch.Size([1, 120])\n",
      "Linear output shape: \t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t torch.Size([1, 84])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape: \\t', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c558acca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated()/1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3a89b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 现在我们已经实现了LeNet，让我们看看LeNet在Fashion-MNIST数据集上的表现。\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "394cd7fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "649"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del net\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef713543",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = d2l.try_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3807c305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d12e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (1): Sigmoid()\n",
       "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): Sigmoid()\n",
       "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (8): Sigmoid()\n",
       "  (9): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (10): Sigmoid()\n",
       "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40907f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.train_ch6??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "41c36f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.rand(size=(256, 1, 28, 28), dtype=torch.float32)\n",
    "X = X.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7be8bc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94ed0548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(y_hat.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3158a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ede6500",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_17160\\4143962260.py\", line 3, in <module>\n",
      "    for i, (X, y) in enumerate(train_iter):\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 652, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1347, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1373, in _process_data\n",
      "    data.reraise()\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\_utils.py\", line 461, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 302, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 52, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 175, in default_collate\n",
      "    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 175, in <listcomp>\n",
      "    return [default_collate(samples) for samples in transposed]  # Backwards compatibility.\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\", line 139, in default_collate\n",
      "    storage = elem.storage()._new_shared(numel, device=elem.device)\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\storage.py\", line 603, in _new_shared\n",
      "    untyped_storage = torch._UntypedStorage._new_shared(size * self.element_size(), device=device)\n",
      "  File \"E:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torch\\storage.py\", line 205, in _new_shared\n",
      "    return cls._new_using_filename_cpu(size)\n",
      "RuntimeError: Couldn't open shared file mapping: <000001F0043E3B92>, error code: <1455>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 在GPU上运行\n",
    "try:\n",
    "    for i, (X, y) in enumerate(train_iter):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        y_hat = net(X)\n",
    "        print('i:%d' % i, y_hat.device, X.shape)\n",
    "except Exception as e:\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "120bfb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:0 cpu torch.Size([256, 1, 28, 28])\n",
      "i:1 cpu torch.Size([256, 1, 28, 28])\n",
      "i:2 cpu torch.Size([256, 1, 28, 28])\n",
      "i:3 cpu torch.Size([256, 1, 28, 28])\n",
      "i:4 cpu torch.Size([256, 1, 28, 28])\n",
      "i:5 cpu torch.Size([256, 1, 28, 28])\n",
      "i:6 cpu torch.Size([256, 1, 28, 28])\n",
      "i:7 cpu torch.Size([256, 1, 28, 28])\n",
      "i:8 cpu torch.Size([256, 1, 28, 28])\n",
      "i:9 cpu torch.Size([256, 1, 28, 28])\n",
      "i:10 cpu torch.Size([256, 1, 28, 28])\n",
      "i:11 cpu torch.Size([256, 1, 28, 28])\n",
      "i:12 cpu torch.Size([256, 1, 28, 28])\n",
      "i:13 cpu torch.Size([256, 1, 28, 28])\n",
      "i:14 cpu torch.Size([256, 1, 28, 28])\n",
      "i:15 cpu torch.Size([256, 1, 28, 28])\n",
      "i:16 cpu torch.Size([256, 1, 28, 28])\n",
      "i:17 cpu torch.Size([256, 1, 28, 28])\n",
      "i:18 cpu torch.Size([256, 1, 28, 28])\n",
      "i:19 cpu torch.Size([256, 1, 28, 28])\n",
      "i:20 cpu torch.Size([256, 1, 28, 28])\n",
      "i:21 cpu torch.Size([256, 1, 28, 28])\n",
      "i:22 cpu torch.Size([256, 1, 28, 28])\n",
      "i:23 cpu torch.Size([256, 1, 28, 28])\n",
      "i:24 cpu torch.Size([256, 1, 28, 28])\n",
      "i:25 cpu torch.Size([256, 1, 28, 28])\n",
      "i:26 cpu torch.Size([256, 1, 28, 28])\n",
      "i:27 cpu torch.Size([256, 1, 28, 28])\n",
      "i:28 cpu torch.Size([256, 1, 28, 28])\n",
      "i:29 cpu torch.Size([256, 1, 28, 28])\n",
      "i:30 cpu torch.Size([256, 1, 28, 28])\n",
      "i:31 cpu torch.Size([256, 1, 28, 28])\n",
      "i:32 cpu torch.Size([256, 1, 28, 28])\n",
      "i:33 cpu torch.Size([256, 1, 28, 28])\n",
      "i:34 cpu torch.Size([256, 1, 28, 28])\n",
      "i:35 cpu torch.Size([256, 1, 28, 28])\n",
      "i:36 cpu torch.Size([256, 1, 28, 28])\n",
      "i:37 cpu torch.Size([256, 1, 28, 28])\n",
      "i:38 cpu torch.Size([256, 1, 28, 28])\n",
      "i:39 cpu torch.Size([256, 1, 28, 28])\n",
      "i:40 cpu torch.Size([256, 1, 28, 28])\n",
      "i:41 cpu torch.Size([256, 1, 28, 28])\n",
      "i:42 cpu torch.Size([256, 1, 28, 28])\n",
      "i:43 cpu torch.Size([256, 1, 28, 28])\n",
      "i:44 cpu torch.Size([256, 1, 28, 28])\n",
      "i:45 cpu torch.Size([256, 1, 28, 28])\n",
      "i:46 cpu torch.Size([256, 1, 28, 28])\n",
      "i:47 cpu torch.Size([256, 1, 28, 28])\n",
      "i:48 cpu torch.Size([256, 1, 28, 28])\n",
      "i:49 cpu torch.Size([256, 1, 28, 28])\n",
      "i:50 cpu torch.Size([256, 1, 28, 28])\n",
      "i:51 cpu torch.Size([256, 1, 28, 28])\n",
      "i:52 cpu torch.Size([256, 1, 28, 28])\n",
      "i:53 cpu torch.Size([256, 1, 28, 28])\n",
      "i:54 cpu torch.Size([256, 1, 28, 28])\n",
      "i:55 cpu torch.Size([256, 1, 28, 28])\n",
      "i:56 cpu torch.Size([256, 1, 28, 28])\n",
      "i:57 cpu torch.Size([256, 1, 28, 28])\n",
      "i:58 cpu torch.Size([256, 1, 28, 28])\n",
      "i:59 cpu torch.Size([256, 1, 28, 28])\n",
      "i:60 cpu torch.Size([256, 1, 28, 28])\n",
      "i:61 cpu torch.Size([256, 1, 28, 28])\n",
      "i:62 cpu torch.Size([256, 1, 28, 28])\n",
      "i:63 cpu torch.Size([256, 1, 28, 28])\n",
      "i:64 cpu torch.Size([256, 1, 28, 28])\n",
      "i:65 cpu torch.Size([256, 1, 28, 28])\n",
      "i:66 cpu torch.Size([256, 1, 28, 28])\n",
      "i:67 cpu torch.Size([256, 1, 28, 28])\n",
      "i:68 cpu torch.Size([256, 1, 28, 28])\n",
      "i:69 cpu torch.Size([256, 1, 28, 28])\n",
      "i:70 cpu torch.Size([256, 1, 28, 28])\n",
      "i:71 cpu torch.Size([256, 1, 28, 28])\n",
      "i:72 cpu torch.Size([256, 1, 28, 28])\n",
      "i:73 cpu torch.Size([256, 1, 28, 28])\n",
      "i:74 cpu torch.Size([256, 1, 28, 28])\n",
      "i:75 cpu torch.Size([256, 1, 28, 28])\n",
      "i:76 cpu torch.Size([256, 1, 28, 28])\n",
      "i:77 cpu torch.Size([256, 1, 28, 28])\n",
      "i:78 cpu torch.Size([256, 1, 28, 28])\n",
      "i:79 cpu torch.Size([256, 1, 28, 28])\n",
      "i:80 cpu torch.Size([256, 1, 28, 28])\n",
      "i:81 cpu torch.Size([256, 1, 28, 28])\n",
      "i:82 cpu torch.Size([256, 1, 28, 28])\n",
      "i:83 cpu torch.Size([256, 1, 28, 28])\n",
      "i:84 cpu torch.Size([256, 1, 28, 28])\n",
      "i:85 cpu torch.Size([256, 1, 28, 28])\n",
      "i:86 cpu torch.Size([256, 1, 28, 28])\n",
      "i:87 cpu torch.Size([256, 1, 28, 28])\n",
      "i:88 cpu torch.Size([256, 1, 28, 28])\n",
      "i:89 cpu torch.Size([256, 1, 28, 28])\n",
      "i:90 cpu torch.Size([256, 1, 28, 28])\n",
      "i:91 cpu torch.Size([256, 1, 28, 28])\n",
      "i:92 cpu torch.Size([256, 1, 28, 28])\n",
      "i:93 cpu torch.Size([256, 1, 28, 28])\n",
      "i:94 cpu torch.Size([256, 1, 28, 28])\n",
      "i:95 cpu torch.Size([256, 1, 28, 28])\n",
      "i:96 cpu torch.Size([256, 1, 28, 28])\n",
      "i:97 cpu torch.Size([256, 1, 28, 28])\n",
      "i:98 cpu torch.Size([256, 1, 28, 28])\n",
      "i:99 cpu torch.Size([256, 1, 28, 28])\n",
      "i:100 cpu torch.Size([256, 1, 28, 28])\n",
      "i:101 cpu torch.Size([256, 1, 28, 28])\n",
      "i:102 cpu torch.Size([256, 1, 28, 28])\n",
      "i:103 cpu torch.Size([256, 1, 28, 28])\n",
      "i:104 cpu torch.Size([256, 1, 28, 28])\n",
      "i:105 cpu torch.Size([256, 1, 28, 28])\n",
      "i:106 cpu torch.Size([256, 1, 28, 28])\n",
      "i:107 cpu torch.Size([256, 1, 28, 28])\n",
      "i:108 cpu torch.Size([256, 1, 28, 28])\n",
      "i:109 cpu torch.Size([256, 1, 28, 28])\n",
      "i:110 cpu torch.Size([256, 1, 28, 28])\n",
      "i:111 cpu torch.Size([256, 1, 28, 28])\n",
      "i:112 cpu torch.Size([256, 1, 28, 28])\n",
      "i:113 cpu torch.Size([256, 1, 28, 28])\n",
      "i:114 cpu torch.Size([256, 1, 28, 28])\n",
      "i:115 cpu torch.Size([256, 1, 28, 28])\n",
      "i:116 cpu torch.Size([256, 1, 28, 28])\n",
      "i:117 cpu torch.Size([256, 1, 28, 28])\n",
      "i:118 cpu torch.Size([256, 1, 28, 28])\n",
      "i:119 cpu torch.Size([256, 1, 28, 28])\n",
      "i:120 cpu torch.Size([256, 1, 28, 28])\n",
      "i:121 cpu torch.Size([256, 1, 28, 28])\n",
      "i:122 cpu torch.Size([256, 1, 28, 28])\n",
      "i:123 cpu torch.Size([256, 1, 28, 28])\n",
      "i:124 cpu torch.Size([256, 1, 28, 28])\n",
      "i:125 cpu torch.Size([256, 1, 28, 28])\n",
      "i:126 cpu torch.Size([256, 1, 28, 28])\n",
      "i:127 cpu torch.Size([256, 1, 28, 28])\n",
      "i:128 cpu torch.Size([256, 1, 28, 28])\n",
      "i:129 cpu torch.Size([256, 1, 28, 28])\n",
      "i:130 cpu torch.Size([256, 1, 28, 28])\n",
      "i:131 cpu torch.Size([256, 1, 28, 28])\n",
      "i:132 cpu torch.Size([256, 1, 28, 28])\n",
      "i:133 cpu torch.Size([256, 1, 28, 28])\n",
      "i:134 cpu torch.Size([256, 1, 28, 28])\n",
      "i:135 cpu torch.Size([256, 1, 28, 28])\n",
      "i:136 cpu torch.Size([256, 1, 28, 28])\n",
      "i:137 cpu torch.Size([256, 1, 28, 28])\n",
      "i:138 cpu torch.Size([256, 1, 28, 28])\n",
      "i:139 cpu torch.Size([256, 1, 28, 28])\n",
      "i:140 cpu torch.Size([256, 1, 28, 28])\n",
      "i:141 cpu torch.Size([256, 1, 28, 28])\n",
      "i:142 cpu torch.Size([256, 1, 28, 28])\n",
      "i:143 cpu torch.Size([256, 1, 28, 28])\n",
      "i:144 cpu torch.Size([256, 1, 28, 28])\n",
      "i:145 cpu torch.Size([256, 1, 28, 28])\n",
      "i:146 cpu torch.Size([256, 1, 28, 28])\n",
      "i:147 cpu torch.Size([256, 1, 28, 28])\n",
      "i:148 cpu torch.Size([256, 1, 28, 28])\n",
      "i:149 cpu torch.Size([256, 1, 28, 28])\n",
      "i:150 cpu torch.Size([256, 1, 28, 28])\n",
      "i:151 cpu torch.Size([256, 1, 28, 28])\n",
      "i:152 cpu torch.Size([256, 1, 28, 28])\n",
      "i:153 cpu torch.Size([256, 1, 28, 28])\n",
      "i:154 cpu torch.Size([256, 1, 28, 28])\n",
      "i:155 cpu torch.Size([256, 1, 28, 28])\n",
      "i:156 cpu torch.Size([256, 1, 28, 28])\n",
      "i:157 cpu torch.Size([256, 1, 28, 28])\n",
      "i:158 cpu torch.Size([256, 1, 28, 28])\n",
      "i:159 cpu torch.Size([256, 1, 28, 28])\n",
      "i:160 cpu torch.Size([256, 1, 28, 28])\n",
      "i:161 cpu torch.Size([256, 1, 28, 28])\n",
      "i:162 cpu torch.Size([256, 1, 28, 28])\n",
      "i:163 cpu torch.Size([256, 1, 28, 28])\n",
      "i:164 cpu torch.Size([256, 1, 28, 28])\n",
      "i:165 cpu torch.Size([256, 1, 28, 28])\n",
      "i:166 cpu torch.Size([256, 1, 28, 28])\n",
      "i:167 cpu torch.Size([256, 1, 28, 28])\n",
      "i:168 cpu torch.Size([256, 1, 28, 28])\n",
      "i:169 cpu torch.Size([256, 1, 28, 28])\n",
      "i:170 cpu torch.Size([256, 1, 28, 28])\n",
      "i:171 cpu torch.Size([256, 1, 28, 28])\n",
      "i:172 cpu torch.Size([256, 1, 28, 28])\n",
      "i:173 cpu torch.Size([256, 1, 28, 28])\n",
      "i:174 cpu torch.Size([256, 1, 28, 28])\n",
      "i:175 cpu torch.Size([256, 1, 28, 28])\n",
      "i:176 cpu torch.Size([256, 1, 28, 28])\n",
      "i:177 cpu torch.Size([256, 1, 28, 28])\n",
      "i:178 cpu torch.Size([256, 1, 28, 28])\n",
      "i:179 cpu torch.Size([256, 1, 28, 28])\n",
      "i:180 cpu torch.Size([256, 1, 28, 28])\n",
      "i:181 cpu torch.Size([256, 1, 28, 28])\n",
      "i:182 cpu torch.Size([256, 1, 28, 28])\n",
      "i:183 cpu torch.Size([256, 1, 28, 28])\n",
      "i:184 cpu torch.Size([256, 1, 28, 28])\n",
      "i:185 cpu torch.Size([256, 1, 28, 28])\n",
      "i:186 cpu torch.Size([256, 1, 28, 28])\n",
      "i:187 cpu torch.Size([256, 1, 28, 28])\n",
      "i:188 cpu torch.Size([256, 1, 28, 28])\n",
      "i:189 cpu torch.Size([256, 1, 28, 28])\n",
      "i:190 cpu torch.Size([256, 1, 28, 28])\n",
      "i:191 cpu torch.Size([256, 1, 28, 28])\n",
      "i:192 cpu torch.Size([256, 1, 28, 28])\n",
      "i:193 cpu torch.Size([256, 1, 28, 28])\n",
      "i:194 cpu torch.Size([256, 1, 28, 28])\n",
      "i:195 cpu torch.Size([256, 1, 28, 28])\n",
      "i:196 cpu torch.Size([256, 1, 28, 28])\n",
      "i:197 cpu torch.Size([256, 1, 28, 28])\n",
      "i:198 cpu torch.Size([256, 1, 28, 28])\n",
      "i:199 cpu torch.Size([256, 1, 28, 28])\n",
      "i:200 cpu torch.Size([256, 1, 28, 28])\n",
      "i:201 cpu torch.Size([256, 1, 28, 28])\n",
      "i:202 cpu torch.Size([256, 1, 28, 28])\n",
      "i:203 cpu torch.Size([256, 1, 28, 28])\n",
      "i:204 cpu torch.Size([256, 1, 28, 28])\n",
      "i:205 cpu torch.Size([256, 1, 28, 28])\n",
      "i:206 cpu torch.Size([256, 1, 28, 28])\n",
      "i:207 cpu torch.Size([256, 1, 28, 28])\n",
      "i:208 cpu torch.Size([256, 1, 28, 28])\n",
      "i:209 cpu torch.Size([256, 1, 28, 28])\n",
      "i:210 cpu torch.Size([256, 1, 28, 28])\n",
      "i:211 cpu torch.Size([256, 1, 28, 28])\n",
      "i:212 cpu torch.Size([256, 1, 28, 28])\n",
      "i:213 cpu torch.Size([256, 1, 28, 28])\n",
      "i:214 cpu torch.Size([256, 1, 28, 28])\n",
      "i:215 cpu torch.Size([256, 1, 28, 28])\n",
      "i:216 cpu torch.Size([256, 1, 28, 28])\n",
      "i:217 cpu torch.Size([256, 1, 28, 28])\n",
      "i:218 cpu torch.Size([256, 1, 28, 28])\n",
      "i:219 cpu torch.Size([256, 1, 28, 28])\n",
      "i:220 cpu torch.Size([256, 1, 28, 28])\n",
      "i:221 cpu torch.Size([256, 1, 28, 28])\n",
      "i:222 cpu torch.Size([256, 1, 28, 28])\n",
      "i:223 cpu torch.Size([256, 1, 28, 28])\n",
      "i:224 cpu torch.Size([256, 1, 28, 28])\n",
      "i:225 cpu torch.Size([256, 1, 28, 28])\n",
      "i:226 cpu torch.Size([256, 1, 28, 28])\n",
      "i:227 cpu torch.Size([256, 1, 28, 28])\n",
      "i:228 cpu torch.Size([256, 1, 28, 28])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:229 cpu torch.Size([256, 1, 28, 28])\n",
      "i:230 cpu torch.Size([256, 1, 28, 28])\n",
      "i:231 cpu torch.Size([256, 1, 28, 28])\n",
      "i:232 cpu torch.Size([256, 1, 28, 28])\n",
      "i:233 cpu torch.Size([256, 1, 28, 28])\n",
      "i:234 cpu torch.Size([96, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 在CPU上运行\n",
    "for i, (X, y) in enumerate(train_iter):\n",
    "    y_hat = net(X)\n",
    "    print('i:%d' % i, y_hat.device, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8964360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2l.evaluate_accuracy_gpu\n",
    "def evaluate_accuracy_gpu(net, data_iter, device=None):\n",
    "    \"\"\"使用GPU计算模型在数据集上的精度\"\"\"\n",
    "    if isinstance(net, nn.Module):\n",
    "        net.eval() # 设置为评估模式\n",
    "        if not device:\n",
    "            device = next(iter(net.parameters())).device\n",
    "    # 正确预测的数量，总预测的数量\n",
    "    metric = d2l.Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(X, list):\n",
    "                # BERT微调所需的（之后将介绍）\n",
    "                X = [x.to(device) for x in X]\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            metric.add(d2l.accuracy(net(X), y), y.numel())\n",
    "    return metric[0] / metric[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd33fcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2l.train_ch6\n",
    "def train_ch6(net, train_iter, test_iter, num_epochs, lr, device):\n",
    "    \"\"\"用GPU训练模型\"\"\"\n",
    "    def init_weights(m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "    net.apply(init_weights)\n",
    "    print('training on', device)\n",
    "    net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    animator = d2l.Animator(xlabel='epoch', xlim=[1, num_epochs],\n",
    "                            legend=['train loss', 'train acc', 'test acc'])\n",
    "    timer, num_batches = d2l.Timer(), len(train_iter)\n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练损失之和，训练准确率之和，样本数\n",
    "        metric = d2l.Accumulator(3)\n",
    "        net.train()\n",
    "        for i, (X, y) in enumerate(train_iter):\n",
    "            timer.start()\n",
    "            optimizer.zero_grad()\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y)\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            with torch.no_grad():\n",
    "                metric.add(l * X.shape[0], d2l.accuracy(y_hat, y), X.shape[0])\n",
    "            timer.stop()\n",
    "            train_l = metric[0] / metric[2]\n",
    "            train_acc = metric[1] / metric[2]\n",
    "            if (i + 1) % (num_batches // 5) == 0 or i == num_batches - 1:\n",
    "                animator.add(epoch + (i + 1) / num_batches,\n",
    "                             (train_l, train_acc, None))\n",
    "        test_acc = evaluate_accuracy_gpu(net, test_iter)\n",
    "        animator.add(epoch + 1, (None, None, test_acc))\n",
    "    print(f'loss {train_l:.3f}, train acc {train_acc:.3f}, '\n",
    "          f'test acc {test_acc:.3f}')\n",
    "    print(f'{metric[2] * num_epochs / timer.sum():.1f} examples/sec'\n",
    "          f'on {str(device)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf33f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.9, 10\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5048085d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# 定义模型\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),  # 经过卷积和池化后，得到的图像尺寸为5*5\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))\n",
    "\n",
    "# 现在我们已经实现了LeNet，让我们看看LeNet在Fashion-MNIST数据集上的表现。\n",
    "batch_size = 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size=batch_size)\n",
    "\n",
    "\n",
    "lr, num_epochs = 0.9, 10\n",
    "d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1207eb69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_iter:\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96a76140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./dataset_cifar10/train\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31.6%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorboard\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# from model import *\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# 准备数据集\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./dataset_cifar10/train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorchvision\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mToTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m test_data \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./dataset_cifar10/test\u001b[39m\u001b[38;5;124m\"\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m     17\u001b[0m                                          transform\u001b[38;5;241m=\u001b[39mtorchvision\u001b[38;5;241m.\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     18\u001b[0m                                          download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# 利用DataLoader加载数据集\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torchvision\\datasets\\cifar.py:65\u001b[0m, in \u001b[0;36mCIFAR10.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain \u001b[38;5;241m=\u001b[39m train  \u001b[38;5;66;03m# training set or test set\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m download:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_integrity():\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found or corrupted. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torchvision\\datasets\\cifar.py:141\u001b[0m, in \u001b[0;36mCIFAR10.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiles already downloaded and verified\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 141\u001b[0m \u001b[43mdownload_and_extract_archive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtgz_md5\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torchvision\\datasets\\utils.py:446\u001b[0m, in \u001b[0;36mdownload_and_extract_archive\u001b[1;34m(url, download_root, extract_root, filename, md5, remove_finished)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m filename:\n\u001b[0;32m    444\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(url)\n\u001b[1;32m--> 446\u001b[0m \u001b[43mdownload_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmd5\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    448\u001b[0m archive \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(download_root, filename)\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marchive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mextract_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torchvision\\datasets\\utils.py:156\u001b[0m, in \u001b[0;36mdownload_url\u001b[1;34m(url, root, filename, md5, max_redirect_hops)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m url \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m to \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m fpath)\n\u001b[1;32m--> 156\u001b[0m     \u001b[43m_urlretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m url[:\u001b[38;5;241m5\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torchvision\\datasets\\utils.py:50\u001b[0m, in \u001b[0;36m_urlretrieve\u001b[1;34m(url, filename, chunk_size)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_urlretrieve\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m, chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m---> 50\u001b[0m         \u001b[43m_save_response_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torchvision\\datasets\\utils.py:39\u001b[0m, in \u001b[0;36m_save_response_content\u001b[1;34m(content, destination, length)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_save_response_content\u001b[39m(\n\u001b[0;32m     34\u001b[0m     content: Iterator[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m     35\u001b[0m     destination: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m     36\u001b[0m     length: Optional[\u001b[38;5;28mint\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     37\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(destination, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fh, tqdm(total\u001b[38;5;241m=\u001b[39mlength) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[1;32m---> 39\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m content:\n\u001b[0;32m     40\u001b[0m             \u001b[38;5;66;03m# filter out keep-alive new chunks\u001b[39;00m\n\u001b[0;32m     41\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[0;32m     42\u001b[0m                 \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\site-packages\\torchvision\\datasets\\utils.py:50\u001b[0m, in \u001b[0;36m_urlretrieve.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_urlretrieve\u001b[39m(url: \u001b[38;5;28mstr\u001b[39m, filename: \u001b[38;5;28mstr\u001b[39m, chunk_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1024\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: USER_AGENT})) \u001b[38;5;28;01mas\u001b[39;00m response:\n\u001b[1;32m---> 50\u001b[0m         _save_response_content(\u001b[38;5;28miter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m), filename, length\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mlength)\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\http\\client.py:463\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[38;5;66;03m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[0;32m    462\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbytearray\u001b[39m(amt)\n\u001b[1;32m--> 463\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b)[:n]\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    466\u001b[0m     \u001b[38;5;66;03m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;66;03m# and self.chunked\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\http\\client.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    502\u001b[0m         b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmemoryview\u001b[39m(b)[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength]\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;66;03m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[0;32m    506\u001b[0m \u001b[38;5;66;03m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[1;32m--> 507\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m n \u001b[38;5;129;01mand\u001b[39;00m b:\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[0;32m    510\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\ssl.py:1242\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1239\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1240\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m   1241\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[1;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mE:\\Anaconda\\anaconda\\envs\\my_env\\lib\\ssl.py:1100\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1098\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1099\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1100\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1101\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1102\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision.datasets\n",
    "from torch import nn\n",
    "from torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# from model import *\n",
    "\n",
    "# 准备数据集\n",
    "train_data = torchvision.datasets.CIFAR10(\"./dataset_cifar10/train\", train=True,\n",
    "                                          transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(\"./dataset_cifar10/test\", train=False,\n",
    "                                         transform=torchvision.transforms.ToTensor(),\n",
    "                                         download=True)\n",
    "\n",
    "# 利用DataLoader加载数据集\n",
    "train_dataloader = DataLoader(train_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)\n",
    "\n",
    "\n",
    "# 创建网络模型\n",
    "class Lyon(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Lyon, self).__init__()\n",
    "        self.model1 = Sequential(\n",
    "            Conv2d(3, 32, 5, padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Conv2d(32, 32, 5, padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Conv2d(32, 64, 5, padding=2),\n",
    "            MaxPool2d(2),\n",
    "            Flatten(),\n",
    "            Linear(1024, 64),\n",
    "            Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "lyon = Lyon()\n",
    "if torch.cuda.is_available():\n",
    "    lyon = lyon.cuda()\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "if torch.cuda.is_available():\n",
    "    loss_fn = loss_fn.cuda()\n",
    "\n",
    "# 优化器\n",
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(lyon.parameters(), lr=learning_rate)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "# 记录训练次数\n",
    "total_train_step = 0\n",
    "# 记录训练次数\n",
    "total_test_step = 0\n",
    "# 训练轮数\n",
    "epoch = 10\n",
    "\n",
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"./logs/train\")\n",
    "\n",
    "start_time = time.time()\n",
    "for i in range(epoch):\n",
    "    print(\"----- 第 {} 轮训练开始 -----\".format(i + 1))\n",
    "    # 训练步骤开始\n",
    "    lyon.train()  # 可以不写\n",
    "    for data in train_dataloader:\n",
    "        imgs, targets = data\n",
    "        if torch.cuda.is_available():\n",
    "            imgs = imgs.cuda()\n",
    "            targets = targets.cuda()\n",
    "        output = lyon(imgs)\n",
    "        loss = loss_fn(output, targets)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_step = total_train_step + 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(end_time - start_time)\n",
    "            print(\"训练次数：{}，Loss：{}\".format(total_train_step, loss))\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "\n",
    "    # 测试步骤开始\n",
    "    lyon.eval()  # 评估步骤开始，可以不写\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs, targets = data\n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda()\n",
    "                targets = targets.cuda()\n",
    "            outputs = lyon(imgs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            accuracy = (outputs.argmax(1) == targets).sum()  # outputs.argmax(1)将输出结果转换为targets的模式\n",
    "            total_test_loss = total_test_loss + loss.item()\n",
    "            total_accuracy = total_accuracy + accuracy\n",
    "\n",
    "    print(\"整体测试集上的Loss：{}\".format(total_test_loss))\n",
    "    print(\"整体测试集上的正确率：{}\".format(total_accuracy))\n",
    "    writer.add_scalar(\"test_loss\", total_test_loss, total_test_step)\n",
    "    total_test_step = total_test_step + 1\n",
    "\n",
    "    torch.save(lyon, \"./train_model/lyon_{}.pth\".format(i))\n",
    "    # 官方推荐模型保存方式\n",
    "    # torch.save(lyon.state_dict(), \"./lyon_{}.pth\".format(i))\n",
    "    print(\"模型已保存！\")\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2e8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
